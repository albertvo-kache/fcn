{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Keras model\n",
    "model = load_model('E:/UDACITY/TERM3/LANE/MLND-Capstone/full_CNN_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Class to average lanes with\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []\n",
    "\n",
    "def road_lines(image):\n",
    "    \"\"\" Takes in a road image, re-sizes for the model,\n",
    "    predicts the lane to be drawn from the model in G color,\n",
    "    recreates an RGB image of a lane and merges with the\n",
    "    original road image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get image ready for feeding into model\n",
    "    small_img = imresize(image, (80, 160, 3))\n",
    "    small_img = np.array(small_img)\n",
    "    small_img = small_img[None,:,:,:]\n",
    "\n",
    "    # Make prediction with neural network (un-normalize value by multiplying by 255)\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    # Add lane prediction to list for averaging\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    # Only using last five for average\n",
    "#    if len(lanes.recent_fit) > 5:\n",
    "    if len(lanes.recent_fit) > 10:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "    # Calculate average detection\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    # Generate fake R & B color dimensions, stack with G\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "    # Re-size to match the original image\n",
    "    lane_image = imresize(lane_drawn, (720, 1280, 3))\n",
    "\n",
    "    # Merge the lane drawing onto the original image\n",
    "    result = cv2.addWeighted(image, 1, lane_image, 1, 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "lanes = Lanes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to save the output video\n",
    "vid_output = 'proj_reg_vid.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"E:/UDACITY/TERM3/LANE/MLND-Capstone/proj_chal_vid.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to save the output video\n",
    "vid_output = 'driving_out_vid.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"E:/UDACITY/TERM3/LANE/MLND-Capstone/driving.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to save the output video\n",
    "vid_output = 'challenge_out.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"E:/UDACITY/TERM3/LANE/MLND-Capstone/challenge.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ffmpeg -i \"E:\\UDACITY\\TERM3\\CarND-Semantic-Segmentation\\runs\\1521710333.3709228\\um_%6d.png\" vid1.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to save the output video\n",
    "vid_output = 'harder_challenge_video_out2.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "clip1 = VideoFileClip(\"E:/UDACITY/TERM3/LANE/MLND-Capstone/harder_challenge_video.mp4\")\n",
    "\n",
    "vid_clip = clip1.fl_image(road_lines)\n",
    "vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (GCC)\n",
      "  configuration: --disable-static --enable-shared --enable-gpl --enable-version3 --enable-sdl2 --enable-bzlib --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libmfx --enable-cuda --enable-cuvid --enable-d3d11va --enable-nvenc --enable-dxva2 --enable-avisynth\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, image2, from 'E:\\UDACITY\\TERM3\\CarND-Semantic-Segmentation\\runs\\OUT2\\um_%6d.png':\n",
      "  Duration: 00:00:00.44, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 576x160, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 000001f5566a7e00] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 000001f5566a7e00] profile High 4:4:4 Predictive, level 1.3, 4:4:4 8-bit\n",
      "[libx264 @ 000001f5566a7e00] 264 - core 155 r2901 7d0ff22 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x1:0x111 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=5 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'vid2.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv444p, 576x160, q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.107.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=   11 fps=0.0 q=-1.0 Lsize=      95kB time=00:00:00.32 bitrate=2420.2kbits/s speed=0.418x    \n",
      "video:94kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.998175%\n",
      "[libx264 @ 000001f5566a7e00] frame I:3     Avg QP:27.63  size:  9900\n",
      "[libx264 @ 000001f5566a7e00] frame P:5     Avg QP:29.52  size:  8582\n",
      "[libx264 @ 000001f5566a7e00] frame B:3     Avg QP:29.89  size:  7525\n",
      "[libx264 @ 000001f5566a7e00] consecutive B-frames: 45.5% 54.5%  0.0%  0.0%\n",
      "[libx264 @ 000001f5566a7e00] mb I  I16..4: 16.3%  0.0% 83.7%\n",
      "[libx264 @ 000001f5566a7e00] mb P  I16..4: 10.8%  0.0% 66.6%  P16..4:  9.9%  8.5%  3.1%  0.0%  0.0%    skip: 1.1%\n",
      "[libx264 @ 000001f5566a7e00] mb B  I16..4:  4.3%  0.0% 51.0%  B16..8: 16.5% 14.6%  5.2%  direct: 4.6%  skip: 3.8%  L0:45.3% L1:43.6% BI:11.1%\n",
      "[libx264 @ 000001f5566a7e00] coded y,u,v intra: 82.4% 42.0% 33.6% inter: 57.0% 7.1% 6.9%\n",
      "[libx264 @ 000001f5566a7e00] i16 v,h,dc,p: 18% 26% 22% 34%\n",
      "[libx264 @ 000001f5566a7e00] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 27% 16%  6%  7%  5% 10%  4% 11%\n",
      "[libx264 @ 000001f5566a7e00] Weighted P-Frames: Y:20.0% UV:20.0%\n",
      "[libx264 @ 000001f5566a7e00] ref P L0: 73.6% 12.9%  8.8%  3.4%  1.3%\n",
      "[libx264 @ 000001f5566a7e00] ref B L0: 95.4%  4.6%\n",
      "[libx264 @ 000001f5566a7e00] kb/s:1730.67\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i \"E:\\UDACITY\\TERM3\\CarND-Semantic-Segmentation\\runs\\OUT2\\um_%6d.png\" vid2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i \"E:\\UDACITY\\TERM3\\CarND-Semantic-Segmentation\\runs\\OUT3\\um_%6d.png\" vid3.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
